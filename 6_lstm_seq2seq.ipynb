{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "\n",
    "(difficult!)\n",
    "\n",
    "Write a sequence-to-sequence LSTM which mirrors all the words in a sentence. For example, if your input is:\n",
    "\n",
    "    the quick brown fox\n",
    "    \n",
    "the model should attempt to output:\n",
    "\n",
    "    eht kciuq nworb xof\n",
    "    \n",
    "Refer to the lecture on how to put together a sequence-to-sequence model, as well as [this article](http://arxiv.org/abs/1409.3215) for best practices.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  ['nywdqq', 'tpejrh', 'bqxsva', 'skwc o', 'dzdwxp']\n",
      "labels: ['qqdwyn', 'hrjept', 'avsxqb', 'o cwks', 'pxwdzd']\n"
     ]
    }
   ],
   "source": [
    "dtype = tf.float32\n",
    "\n",
    "GO = '>'\n",
    "EOS = '$'\n",
    "\n",
    "special_chars = [GO, EOS]\n",
    "#safe_chars = list(' abc')\n",
    "safe_chars = list(' ' + string.ascii_lowercase)\n",
    "alphabet = special_chars + safe_chars\n",
    "alphabet_size = len(alphabet)\n",
    "\n",
    "char_to_id_map = {c: i for i, c in enumerate(alphabet)}\n",
    "\n",
    "\n",
    "def char_to_id(char):\n",
    "    try:\n",
    "        return char_to_id_map[char]\n",
    "    except IndexError:\n",
    "        print('Unknown character: {}'.format(char))\n",
    "        return 0\n",
    "\n",
    "\n",
    "def id_to_char(char_id):\n",
    "    return alphabet[char_id]\n",
    "\n",
    "\n",
    "def next_batch(batch_size=1000):\n",
    "    sentence_size = np.random.randint(low=4, high=11)\n",
    "    batch = np.zeros([batch_size, sentence_size, alphabet_size])\n",
    "    chars = np.random.choice(safe_chars, size=batch_size * sentence_size)\n",
    "    for i, char in enumerate(chars):\n",
    "        batch_i, sentence_i = divmod(i, sentence_size)\n",
    "        batch[batch_i, sentence_i, char_to_id(char)] = 1.0\n",
    "    return batch, batch[:, ::-1, :]\n",
    "\n",
    "\n",
    "def probabilities_to_sentence(probs):\n",
    "    mask = np.sum(probs, 1) != 0.0\n",
    "    sentence_length = np.sum(mask)\n",
    "    masked_probs = probs[:sentence_length]\n",
    "    sentence = ''.join([id_to_char(c) for c in np.argmax(masked_probs, 1)])\n",
    "    zeros = '0' * (len(probs) - sentence_length)\n",
    "    return sentence + zeros\n",
    "\n",
    "\n",
    "def batch_to_sentences(batch):\n",
    "    return [probabilities_to_sentence(probs) for probs in batch]\n",
    "\n",
    "\n",
    "batch, labels = next_batch(5)\n",
    "print('batch: ', batch_to_sentences(batch))\n",
    "print('labels:', batch_to_sentences(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lstm_size = 128\n",
    "initializer_scale = 0.1\n",
    "learning_rate = 0.001\n",
    "optimizer = 'Adam'\n",
    "clip_gradients = 5.0\n",
    "dropout_keep_prob = 0.6\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, mode):\n",
    "        assert mode in ['train', 'eval', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "    def build_graph(self):\n",
    "        self._build_inputs()\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        if self.mode != 'inference':\n",
    "            self._build_loss()\n",
    "        if self.mode == 'train':\n",
    "            self._build_train_op()\n",
    "\n",
    "    def _build_inputs(self):\n",
    "        self.sentences = tf.placeholder(\n",
    "            dtype, [None, None, alphabet_size],\n",
    "            name='sentences')\n",
    "        self.labels = tf.placeholder(\n",
    "            dtype, [None, None, alphabet_size],\n",
    "            name='labels')\n",
    "        with tf.variable_scope('batch_size'):\n",
    "            self.batch_size = tf.shape(self.sentences)[0]\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        with tf.variable_scope('encoder'):\n",
    "            self.encoder_inputs = tf.identity(self.sentences, name='inputs')\n",
    "            self.encoder_num_rolls = tf.reduce_sum(\n",
    "                self.encoder_inputs, axis=[1, 2], name='num_rolls')\n",
    "            _, self.encoder_output_state = tf.nn.dynamic_rnn(\n",
    "                cell=self._make_cell(),\n",
    "                inputs=self.encoder_inputs,\n",
    "                sequence_length=self.encoder_num_rolls,\n",
    "                dtype=dtype)\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        with tf.variable_scope('decoder'):\n",
    "            with tf.variable_scope('inputs'):\n",
    "                self.decoder_inputs = self._prepend_go(\n",
    "                    self.labels, name='inputs')\n",
    "            self.decoder_num_rolls = tf.reduce_sum(\n",
    "                self.decoder_inputs, axis=[1, 2], name='num_rolls')\n",
    "            self.decoder_input_state = self.encoder_output_state\n",
    "            self.decoder_outputs, self.decoder_output_state = tf.nn.dynamic_rnn(\n",
    "                cell=self._make_cell(),\n",
    "                inputs=self.decoder_inputs,\n",
    "                sequence_length=self.decoder_num_rolls,\n",
    "                initial_state=self.decoder_input_state)\n",
    "\n",
    "        with tf.variable_scope('logits'):\n",
    "            outputs_flat = tf.reshape(\n",
    "                self.decoder_outputs, [-1, lstm_size], name='outputs_flat')\n",
    "            self.logits_flat = tf.contrib.layers.fully_connected(\n",
    "                inputs=outputs_flat,\n",
    "                num_outputs=alphabet_size,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.random_uniform_initializer(\n",
    "                    minval=-initializer_scale,\n",
    "                    maxval=initializer_scale))\n",
    "            with tf.variable_scope('shape'):\n",
    "                shape = tf.shape(self.decoder_inputs)\n",
    "                batch_size = shape[0]\n",
    "                num_rolls = shape[1]\n",
    "                logits_shape = [batch_size, num_rolls, alphabet_size]\n",
    "            self.logits = tf.reshape(\n",
    "                self.logits_flat, logits_shape, name='logits')\n",
    "\n",
    "        with tf.variable_scope('probs'):\n",
    "            self.probs = tf.nn.softmax(self.logits, name='probs')\n",
    "\n",
    "    def _build_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            labels_eos = self._append_eos(self.labels, 'labels_eos')\n",
    "            labels_eos_flat = tf.reshape(\n",
    "                labels_eos, [-1, alphabet_size], name='labels_eos_flat')\n",
    "            mask = tf.reduce_sum(labels_eos_flat, axis=1, name='mask')\n",
    "            unmasked_losses = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=labels_eos_flat, logits=self.logits_flat, name='unmasked_losses')\n",
    "            batch_loss = tf.reduce_mean(\n",
    "                unmasked_losses * mask, name='batch_loss')\n",
    "            tf.losses.add_loss(batch_loss)\n",
    "            self.loss = tf.losses.get_total_loss()\n",
    "\n",
    "    def _build_train_op(self):\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        self.train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=self.loss,\n",
    "            global_step=global_step,\n",
    "            learning_rate=learning_rate,\n",
    "            optimizer=optimizer,\n",
    "            clip_gradients=clip_gradients)\n",
    "\n",
    "    def _make_cell(self):\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        keep_prob = dropout_keep_prob if self.mode == 'train' else 1.0\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "        return cell\n",
    "\n",
    "    def _prepend_go(self, labels, name=None):\n",
    "        return tf.concat([\n",
    "            self._broadcast_char(GO, name='special_go'),\n",
    "            labels,\n",
    "        ], axis=1, name=name)\n",
    "\n",
    "    def _append_eos(self, labels, name=None):\n",
    "        return tf.concat([\n",
    "            labels,\n",
    "            self._broadcast_char(EOS, name='special_eos'),\n",
    "        ], axis=1, name=name)\n",
    "\n",
    "    def _broadcast_char(self, char, name=None):\n",
    "        with tf.variable_scope(name or 'broadcast_char'):\n",
    "            result = tf.one_hot(\n",
    "                char_to_id(char), alphabet_size, dtype=dtype)\n",
    "            result = tf.tile(result, [self.batch_size])\n",
    "            result = tf.reshape(\n",
    "                result, [self.batch_size, 1, alphabet_size], name=name)\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 1     batch loss: 3.3697   valid loss: 6.7395   valid \"accuracy\": 0.0000  \n",
      "inputs:  ['egysc', ' qcnf', 'dwzza', 'ljist', 'v wir']\n",
      "labels:  ['csyge$', 'fncq $', 'azzwd$', 'tsijl$', 'riw v$']\n",
      "outputs: ['abytty', 'msajba', 'owwhub', 'hzttyy', 'oyybaa']\n",
      "INFO:tensorflow:Saving checkpoints for 20 into /tmp/lstm_seq2seq/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/tmp/lstm_seq2seq'\n",
    "\n",
    "\n",
    "def train(num_steps=None, max_variation=None):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        model = Model(mode='train')\n",
    "        model.build_graph()\n",
    "        hooks = [\n",
    "            tf.train.StopAtStepHook(num_steps=num_steps)\n",
    "            if num_steps is not None else None,\n",
    "            StopWhenPlateauHook(model.loss, max_variation=max_variation)\n",
    "            if max_variation is not None else None,\n",
    "            tf.train.NanTensorHook(model.loss),\n",
    "            LoggerHook(model),\n",
    "        ]\n",
    "        hooks = [hook for hook in hooks if hook is not None]\n",
    "        with tf.train.MonitoredTrainingSession(\n",
    "                checkpoint_dir=train_dir,\n",
    "                save_checkpoint_secs=60,\n",
    "                hooks=hooks) as sess:\n",
    "            while not sess.should_stop():\n",
    "                batch_sentences, batch_labels = next_batch()\n",
    "                _, batch_loss = sess.run(\n",
    "                    [model.train_op, model.loss],\n",
    "                    feed_dict={\n",
    "                        model.sentences: batch_sentences,\n",
    "                        model.labels: batch_labels,\n",
    "                    })\n",
    "\n",
    "\n",
    "class LoggerHook(tf.train.SessionRunHook):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def begin(self):\n",
    "        self.valid_sentences, self.valid_labels = next_batch(100)\n",
    "        self.valid_model = Model(mode='eval')\n",
    "        with tf.name_scope('eval'), tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
    "            self.valid_model.build_graph()\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        return tf.train.SessionRunArgs({\n",
    "            'step': tf.contrib.framework.get_global_step(),\n",
    "            'batch_loss': self.model.loss,\n",
    "            'valid_loss': self.valid_model.loss,\n",
    "            'valid_probs': self.valid_model.probs,\n",
    "        }, feed_dict={\n",
    "            self.valid_model.sentences: self.valid_sentences,\n",
    "            self.valid_model.labels: self.valid_labels,\n",
    "        })\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        step = run_values.results['step']\n",
    "        if not (step % 100 == 0 or step == 1):\n",
    "            return\n",
    "        batch_loss = run_values.results['batch_loss']\n",
    "        valid_loss = run_values.results['valid_loss']\n",
    "        valid_probs = run_values.results['valid_probs']\n",
    "        valid_predictions = np.argmax(valid_probs, axis=2)[:, :-1]\n",
    "        num_ok = np.sum(np.all(valid_predictions == np.argmax(\n",
    "            self.valid_labels, axis=2), axis=1))\n",
    "        print('step: {:<5} batch loss: {:<8.4f} valid loss: {:<8.4f} valid \"accuracy\": {:<8.4f}'.format(\n",
    "            step, batch_loss, valid_loss, num_ok / len(valid_predictions)))\n",
    "        n = 5\n",
    "        print('inputs: ', batch_to_sentences(\n",
    "            self.valid_sentences[:n, :, :]))\n",
    "        print('labels: ', [\n",
    "              x + '$' for x in batch_to_sentences(self.valid_labels[:n, :, :])])\n",
    "        print('outputs:', batch_to_sentences(valid_probs[:n, :, :]))\n",
    "\n",
    "\n",
    "class StopWhenPlateauHook(tf.train.SessionRunHook):\n",
    "    \"\"\"Hook that requests stop when the metric reaches a plateau.\"\"\"\n",
    "\n",
    "    def __init__(self, metric, *, max_variation, num_steps=50):\n",
    "        self._metric = metric\n",
    "        self._max_variation = max_variation\n",
    "        self._history = collections.deque(maxlen=num_steps)\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        return tf.train.SessionRunArgs(self._metric)\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        metric = run_values.results\n",
    "        self._history.append(metric)\n",
    "        if len(self._history) < self._history.maxlen:\n",
    "            return\n",
    "        variation = max(self._history) - min(self._history)\n",
    "        if variation < self._max_variation:\n",
    "            run_context.request_stop()\n",
    "\n",
    "\n",
    "train(num_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  ['osymrydjqz']\n",
      "labels:  ['zqjdyrmyso']\n",
      "outputs: ['$$$$$$$$$$$']\n",
      "\n",
      "1 encoder_inputs\n",
      "[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]]\n",
      "\n",
      "2 encoder_num_rolls\n",
      "[ 10.]\n",
      "\n",
      "3 decoder_inputs\n",
      "[[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]\n",
      "\n",
      "4 decoder_num_rolls\n",
      "[ 11.]\n",
      "\n",
      "5 decoder_outputs\n",
      "[[[ 0.018  0.073  0.002 ..., -0.048  0.082  0.094]\n",
      "  [ 0.011  0.063 -0.012 ..., -0.076  0.049  0.126]\n",
      "  [ 0.036  0.087 -0.052 ..., -0.063  0.061  0.151]\n",
      "  ..., \n",
      "  [ 0.328  0.454 -0.297 ...,  0.011  0.404  0.36 ]\n",
      "  [ 0.353  0.517 -0.346 ...,  0.048  0.486  0.425]\n",
      "  [ 0.382  0.563 -0.415 ...,  0.068  0.603  0.439]]]\n",
      "\n",
      "batch_probs\n",
      "[[[ 0.025  0.044  0.033  0.035  0.036  0.034  0.035  0.035  0.036  0.033\n",
      "    0.033  0.032  0.034  0.036  0.036  0.036  0.035  0.038  0.033  0.036\n",
      "    0.035  0.033  0.035  0.034  0.032  0.032  0.032  0.036  0.036]\n",
      "  [ 0.024  0.055  0.034  0.035  0.036  0.033  0.035  0.034  0.035  0.031\n",
      "    0.033  0.032  0.033  0.036  0.035  0.035  0.034  0.038  0.033  0.036\n",
      "    0.034  0.033  0.036  0.034  0.032  0.032  0.032  0.036  0.036]\n",
      "  [ 0.023  0.071  0.033  0.036  0.036  0.032  0.035  0.034  0.034  0.029\n",
      "    0.032  0.031  0.033  0.037  0.034  0.034  0.033  0.037  0.032  0.035\n",
      "    0.033  0.032  0.037  0.033  0.032  0.031  0.031  0.035  0.034]\n",
      "  [ 0.021  0.094  0.032  0.036  0.035  0.03   0.034  0.033  0.033  0.027\n",
      "    0.031  0.03   0.032  0.037  0.032  0.034  0.031  0.038  0.03   0.034\n",
      "    0.031  0.032  0.037  0.034  0.031  0.03   0.031  0.035  0.034]\n",
      "  [ 0.019  0.134  0.032  0.036  0.034  0.028  0.033  0.031  0.032  0.025\n",
      "    0.03   0.029  0.031  0.036  0.031  0.032  0.029  0.037  0.029  0.033\n",
      "    0.028  0.031  0.037  0.031  0.029  0.028  0.03   0.033  0.032]\n",
      "  [ 0.016  0.194  0.029  0.034  0.031  0.025  0.032  0.029  0.03   0.022\n",
      "    0.028  0.028  0.029  0.034  0.028  0.031  0.027  0.035  0.026  0.03\n",
      "    0.026  0.03   0.037  0.03   0.026  0.026  0.028  0.03   0.03 ]\n",
      "  [ 0.013  0.28   0.026  0.032  0.027  0.022  0.028  0.026  0.027  0.019\n",
      "    0.025  0.025  0.026  0.031  0.025  0.027  0.024  0.032  0.023  0.027\n",
      "    0.022  0.027  0.036  0.026  0.023  0.022  0.025  0.027  0.026]\n",
      "  [ 0.01   0.389  0.022  0.028  0.023  0.018  0.024  0.022  0.023  0.015\n",
      "    0.021  0.022  0.023  0.027  0.021  0.023  0.021  0.028  0.019  0.022\n",
      "    0.017  0.024  0.032  0.022  0.018  0.019  0.021  0.022  0.023]\n",
      "  [ 0.007  0.508  0.017  0.023  0.018  0.014  0.02   0.018  0.019  0.012\n",
      "    0.017  0.018  0.018  0.022  0.017  0.019  0.017  0.023  0.015  0.018\n",
      "    0.013  0.02   0.028  0.018  0.014  0.015  0.017  0.017  0.019]\n",
      "  [ 0.005  0.61   0.014  0.019  0.014  0.011  0.015  0.014  0.015  0.009\n",
      "    0.014  0.015  0.014  0.018  0.013  0.015  0.013  0.018  0.011  0.013\n",
      "    0.01   0.016  0.023  0.014  0.011  0.012  0.014  0.013  0.015]\n",
      "  [ 0.004  0.685  0.011  0.015  0.011  0.009  0.012  0.012  0.012  0.007\n",
      "    0.011  0.012  0.012  0.014  0.011  0.012  0.011  0.015  0.009  0.011\n",
      "    0.008  0.013  0.02   0.011  0.008  0.01   0.011  0.011  0.013]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect():\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        model = Model(mode='inference')\n",
    "        model.build_graph()\n",
    "        with tf.train.MonitoredSession(\n",
    "                session_creator=tf.train.ChiefSessionCreator(\n",
    "                    checkpoint_dir=train_dir)) as sess:\n",
    "            batch_sentences, batch_labels = next_batch(batch_size=1)\n",
    "            results = sess.run(\n",
    "                {\n",
    "                    '1 encoder_inputs': model.encoder_inputs,\n",
    "                    '2 encoder_num_rolls': model.encoder_num_rolls,\n",
    "                    '3 decoder_inputs': model.decoder_inputs,\n",
    "                    '4 decoder_num_rolls': model.decoder_num_rolls,\n",
    "                    '5 decoder_outputs': model.decoder_outputs,\n",
    "                    'batch_probs': model.probs,\n",
    "                },\n",
    "                feed_dict={\n",
    "                    model.sentences: batch_sentences,\n",
    "                    model.labels: batch_labels,\n",
    "                })\n",
    "            print('inputs: ', batch_to_sentences(batch_sentences))\n",
    "            print('labels: ', batch_to_sentences(batch_labels))\n",
    "            print('outputs:', batch_to_sentences(results['batch_probs']))\n",
    "            print()\n",
    "            for k, v in sorted(results.items()):\n",
    "                print(k)\n",
    "                print(v)\n",
    "                print()\n",
    "\n",
    "\n",
    "inspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 21 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 100   batch loss: 3.0244   valid loss: 6.1390   valid \"accuracy\": 0.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['zzzzzzzz$$', 'tttttt$$$$', 'kkkkk$$$$$', 'nnnnnnnb$$', 'ftttttt$$$']\n",
      "INFO:tensorflow:global_step/sec: 1.92986\n",
      "INFO:tensorflow:Saving checkpoints for 139 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 200   batch loss: 2.3228   valid loss: 4.9937   valid \"accuracy\": 0.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['nnnnnnnnn$', 'aaaaaaaa$$', 'ppppppppp$', 'nnnnnnnnn$', 'pppppttt$$']\n",
      "INFO:tensorflow:global_step/sec: 2.10587\n",
      "INFO:tensorflow:Saving checkpoints for 263 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 300   batch loss: 2.0604   valid loss: 4.4223   valid \"accuracy\": 0.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['oooooonnn$', 'paaaayyy$$', 'ppppppss$$', 'ooooooooo$', 'eeeppoooo$']\n",
      "INFO:tensorflow:global_step/sec: 1.95515\n",
      "INFO:tensorflow:Saving checkpoints for 382 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 400   batch loss: 2.1329   valid loss: 4.1880   valid \"accuracy\": 0.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['ooooohhhh$', 'fmmammmp$$', 'ppppppss$$', 'oooooonn$$', 'ezezepof$$']\n",
      "INFO:tensorflow:global_step/sec: 1.95691\n",
      "INFO:tensorflow:Saving checkpoints for 499 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 500   batch loss: 1.2213   valid loss: 2.6479   valid \"accuracy\": 0.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['mooooohhh$', 'emmammmm$$', 'pppppphy$$', 'ooooooo  $', 'ezzzzpof$$']\n",
      "INFO:tensorflow:global_step/sec: 1.95163\n",
      "step: 600   batch loss: 0.7905   valid loss: 1.7501   valid \"accuracy\": 0.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['umoomohln$', 'esmacmmwp$', 'qppppphys$', 'mdoooonn $', 'eezzzpof$$']\n",
      "INFO:tensorflow:Saving checkpoints for 619 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.00332\n",
      "step: 700   batch loss: 1.1954   valid loss: 2.0029   valid \"accuracy\": 0.0100  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyoooohnn$', 'esmacywwp$', 'qpzpahhy$$', 'mdoooonn $', 'eeezzpff$$']\n",
      "INFO:tensorflow:global_step/sec: 1.99583\n",
      "INFO:tensorflow:Saving checkpoints for 740 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 800   batch loss: 0.3128   valid loss: 0.7621   valid \"accuracy\": 0.4000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjooolln$', 'esmacymwp$', 'qyzpaphys$', 'mdcoooen $', 'eezzzpof$$']\n",
      "INFO:tensorflow:global_step/sec: 1.90229\n",
      "INFO:tensorflow:Saving checkpoints for 855 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 900   batch loss: 0.2941   valid loss: 0.6988   valid \"accuracy\": 0.3800  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjooohln$', 'esmacymwp$', 'qyzppphys$', 'mdcoooen $', 'eeezzpof$$']\n",
      "INFO:tensorflow:global_step/sec: 2.02665\n",
      "INFO:tensorflow:Saving checkpoints for 978 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 1000  batch loss: 0.2292   valid loss: 0.5256   valid \"accuracy\": 0.5700  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdcooonn $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 2.01723\n",
      "INFO:tensorflow:Saving checkpoints for 1098 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 1100  batch loss: 0.4329   valid loss: 0.6649   valid \"accuracy\": 0.6800  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdcoooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.98746\n",
      "step: 1200  batch loss: 0.1103   valid loss: 0.3089   valid \"accuracy\": 0.7400  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohnn$', 'esmacywwp$', 'qyzpaphys$', 'mdcooonnn$', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 1215 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.94869\n",
      "step: 1300  batch loss: 0.1930   valid loss: 0.3456   valid \"accuracy\": 0.7900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdcoooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.93179\n",
      "INFO:tensorflow:Saving checkpoints for 1331 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 1400  batch loss: 0.1472   valid loss: 0.3241   valid \"accuracy\": 0.6700  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacywwp$', 'qyzpaphys$', 'mdcoooen $', 'ebezzpffv$']\n",
      "INFO:tensorflow:global_step/sec: 1.98023\n",
      "INFO:tensorflow:Saving checkpoints for 1449 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 1500  batch loss: 0.0686   valid loss: 0.2494   valid \"accuracy\": 0.6100  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohlo$', 'esmacymwp$', 'qyzpaphys$', 'mdcoooen $', 'ebezzpott$']\n",
      "INFO:tensorflow:global_step/sec: 1.91547\n",
      "INFO:tensorflow:Saving checkpoints for 1564 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 1600  batch loss: 0.3909   valid loss: 0.5711   valid \"accuracy\": 0.4900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohl$$', 'esmacymwp$', 'qyzpaphy$$', 'mdcoooen $', 'ebezzpof$$']\n",
      "INFO:tensorflow:global_step/sec: 1.89914\n",
      "INFO:tensorflow:Saving checkpoints for 1682 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 1700  batch loss: 0.0854   valid loss: 0.2053   valid \"accuracy\": 0.7700  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphss$', 'mdcoooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 2.024\n",
      "step: 1800  batch loss: 0.3100   valid loss: 0.7254   valid \"accuracy\": 0.8500  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohlnd', 'esmacymwpd', 'qyzpaphyb$', 'mdchooen v', 'ebezzpoftd']\n",
      "INFO:tensorflow:Saving checkpoints for 1801 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.93001\n",
      "step: 1900  batch loss: 0.0351   valid loss: 0.1224   valid \"accuracy\": 0.8500  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 1918 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.95132\n",
      "step: 2000  batch loss: 0.0255   valid loss: 0.0734   valid \"accuracy\": 0.9600  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.95799\n",
      "INFO:tensorflow:Saving checkpoints for 2035 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 2100  batch loss: 0.0748   valid loss: 0.4343   valid \"accuracy\": 0.2600  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohl$$', 'esmacyww$$', 'qyzpaphs$$', 'mdcoooen$$', 'ebezzpo$$$']\n",
      "INFO:tensorflow:global_step/sec: 1.95674\n",
      "INFO:tensorflow:Saving checkpoints for 2153 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 2200  batch loss: 0.0620   valid loss: 0.1061   valid \"accuracy\": 0.9600  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.9342\n",
      "INFO:tensorflow:Saving checkpoints for 2271 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 2300  batch loss: 0.1283   valid loss: 0.2006   valid \"accuracy\": 0.8900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 2.0399\n",
      "INFO:tensorflow:Saving checkpoints for 2395 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 2400  batch loss: 0.2038   valid loss: 0.2726   valid \"accuracy\": 0.8900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdcoooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.99211\n",
      "step: 2500  batch loss: 0.1055   valid loss: 0.1361   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 2515 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.98662\n",
      "step: 2600  batch loss: 0.0288   valid loss: 0.0555   valid \"accuracy\": 0.9900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.91048\n",
      "INFO:tensorflow:Saving checkpoints for 2629 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 2700  batch loss: 0.0125   valid loss: 0.0445   valid \"accuracy\": 0.9700  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooe  $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.92829\n",
      "INFO:tensorflow:Saving checkpoints for 2746 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 2800  batch loss: 0.0425   valid loss: 0.0696   valid \"accuracy\": 0.9900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.99505\n",
      "INFO:tensorflow:Saving checkpoints for 2864 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 2900  batch loss: 0.0336   valid loss: 0.0847   valid \"accuracy\": 0.9300  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen o', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.94891\n",
      "INFO:tensorflow:Saving checkpoints for 2983 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 3000  batch loss: 0.0479   valid loss: 0.0665   valid \"accuracy\": 0.9900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.96924\n",
      "step: 3100  batch loss: 0.0968   valid loss: 0.1918   valid \"accuracy\": 0.7200  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacympp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 3102 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.96957\n",
      "step: 3200  batch loss: 0.0571   valid loss: 0.0708   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.9832\n",
      "INFO:tensorflow:Saving checkpoints for 3221 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 3300  batch loss: 0.0605   valid loss: 0.0721   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.88163\n",
      "INFO:tensorflow:Saving checkpoints for 3335 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 3400  batch loss: 0.0269   valid loss: 0.0360   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.87647\n",
      "INFO:tensorflow:Saving checkpoints for 3448 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 3500  batch loss: 0.0061   valid loss: 0.0132   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.90744\n",
      "INFO:tensorflow:Saving checkpoints for 3561 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 3600  batch loss: 0.0214   valid loss: 0.0444   valid \"accuracy\": 0.9400  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphy$$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.92762\n",
      "INFO:tensorflow:Saving checkpoints for 3683 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 3700  batch loss: 0.0378   valid loss: 0.0456   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 2.01984\n",
      "step: 3800  batch loss: 0.1202   valid loss: 0.2428   valid \"accuracy\": 0.8200  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchood  h', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 3802 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.9759\n",
      "step: 3900  batch loss: 0.0808   valid loss: 0.0964   valid \"accuracy\": 0.9900  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 2.03455\n",
      "INFO:tensorflow:Saving checkpoints for 3924 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 4000  batch loss: 0.0043   valid loss: 0.0110   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.99438\n",
      "INFO:tensorflow:Saving checkpoints for 4044 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 4100  batch loss: 0.0126   valid loss: 0.0178   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.96795\n",
      "INFO:tensorflow:Saving checkpoints for 4164 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 4200  batch loss: 0.0426   valid loss: 0.0951   valid \"accuracy\": 0.8100  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.98049\n",
      "INFO:tensorflow:Saving checkpoints for 4284 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 4300  batch loss: 0.0187   valid loss: 0.0275   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.97472\n",
      "step: 4400  batch loss: 0.0251   valid loss: 0.0448   valid \"accuracy\": 0.9700  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 4401 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.95387\n",
      "step: 4500  batch loss: 0.0029   valid loss: 0.0096   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 4520 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.97315\n",
      "step: 4600  batch loss: 0.0033   valid loss: 0.0087   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.90373\n",
      "INFO:tensorflow:Saving checkpoints for 4636 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 4700  batch loss: 0.1300   valid loss: 0.1565   valid \"accuracy\": 0.9500  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 1.97058\n",
      "INFO:tensorflow:Saving checkpoints for 4754 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 4800  batch loss: 0.0151   valid loss: 0.0226   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 2.00027\n",
      "INFO:tensorflow:Saving checkpoints for 4876 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 4900  batch loss: 0.0270   valid loss: 0.0308   valid \"accuracy\": 1.0000  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:global_step/sec: 2.00677\n",
      "INFO:tensorflow:Saving checkpoints for 4996 into /tmp/lstm_seq2seq/model.ckpt.\n",
      "step: 5000  batch loss: 0.0042   valid loss: 0.1689   valid \"accuracy\": 0.7100  \n",
      "inputs:  ['nlhomzjyu', 'pwmycamse', 'syhpapzyq', ' neoohcdm', 'tfopzzebe']\n",
      "labels:  ['uyjzmohln$', 'esmacymwp$', 'qyzpaphys$', 'mdchooen $', 'ebezzpoft$']\n",
      "outputs: ['uyjzmohll$', 'esmacymwp$', 'qyzpaphysq', 'mdchooen $', 'ebezzpoft$']\n",
      "INFO:tensorflow:Saving checkpoints for 5020 into /tmp/lstm_seq2seq/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "train(num_steps=5000, max_variation=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: abc\n",
      "target:   cba\n",
      "c p=1.00\n",
      "b p=1.00\n",
      "a p=1.00\n",
      "output:   cba\n",
      "\n",
      "sentence: tiny little\n",
      "target:   elttil ynit\n",
      "e p=1.00\n",
      "l p=0.97\n",
      "t p=1.00\n",
      "t p=0.96\n",
      "i p=0.98\n",
      "l p=1.00\n",
      "  p=1.00\n",
      "y p=1.00\n",
      "n p=1.00\n",
      "i p=0.99\n",
      "t p=1.00\n",
      "output:   elttil ynit\n",
      "\n",
      "sentence: pony\n",
      "target:   ynop\n",
      "y p=1.00\n",
      "n p=1.00\n",
      "o p=1.00\n",
      "p p=1.00\n",
      "output:   ynop\n",
      "\n",
      "sentence: the quick brown fox\n",
      "target:   xof nworb kciuq eht\n",
      "x p=1.00\n",
      "o p=0.51\n",
      "f p=1.00\n",
      "n p=0.61\n",
      "  p=1.00\n",
      "w p=1.00\n",
      "o p=0.96\n",
      "r p=0.98\n",
      "c p=1.00\n",
      "output:   xofn worc\n",
      "\n",
      "sentence: abcdefghijklmnopqrstuvwxyz\n",
      "target:   zyxwvutsrqponmlkjihgfedcba\n",
      "z p=0.99\n",
      "y p=0.99\n",
      "x p=1.00\n",
      "w p=1.00\n",
      "v p=0.99\n",
      "u p=0.60\n",
      "t p=0.93\n",
      "s p=1.00\n",
      "r p=0.76\n",
      "p p=0.98\n",
      "q p=0.78\n",
      "o p=1.00\n",
      "output:   zyxwvutsrpqo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def encode_char(c):\n",
    "    result = np.zeros([alphabet_size])\n",
    "    result[char_to_id(c)] = 1.0\n",
    "    return result\n",
    "\n",
    "\n",
    "def encode_sentence(sentence):\n",
    "    return np.stack([encode_char(c) for c in sentence])\n",
    "\n",
    "\n",
    "def decode_char(probs):\n",
    "    if np.all(probs == 0.0):\n",
    "        return '0'\n",
    "    return id_to_char(np.argmax(probs))\n",
    "\n",
    "\n",
    "def run_greedy(sentence):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        model = Model(mode='inference')\n",
    "        model.build_graph()\n",
    "        with tf.train.MonitoredSession(\n",
    "                session_creator=tf.train.ChiefSessionCreator(checkpoint_dir=train_dir)) as sess:\n",
    "            state = sess.run(\n",
    "                model.encoder_output_state,\n",
    "                feed_dict={\n",
    "                    model.sentences: [encode_sentence(sentence)],\n",
    "                })\n",
    "            c = GO\n",
    "            result = []\n",
    "            while True:\n",
    "                state, probs = sess.run(\n",
    "                    [model.decoder_output_state, model.probs],\n",
    "                    feed_dict={\n",
    "                        model.decoder_input_state: state,\n",
    "                        model.decoder_inputs: [encode_sentence(c)],\n",
    "                    })\n",
    "                probs = np.squeeze(probs)\n",
    "                c = decode_char(probs)\n",
    "                if c == EOS:\n",
    "                    break\n",
    "                result.append(c)\n",
    "                print('{c} p={p:.2f}'.format(c=c, p=np.max(probs)))\n",
    "            return ''.join(result)\n",
    "\n",
    "\n",
    "for sentence in ['abc', 'tiny little', 'pony', 'the quick brown fox', string.ascii_lowercase]:\n",
    "    print('sentence: {}'.format(sentence))\n",
    "    print('target:   {}'.format(''.join(reversed(sentence))))\n",
    "    print('output:   {}'.format(run_greedy(sentence)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:        abc\n",
      "target:          cba\n",
      "output: p=0.9936 cba\n",
      "output: p=0.0016 bca\n",
      "output: p=0.0006 cbap\n",
      "output: p=0.0005 cbas\n",
      "output: p=0.0004 cbay\n",
      "output: p=0.0003 cba \n",
      "output: p=0.0003 cbam\n",
      "output: p=0.0002 cbad\n",
      "output: p=0.0002 cbao\n",
      "output: p=0.0002 cbav\n",
      "\n",
      "sentence:        tiny little\n",
      "target:          elttil ynit\n",
      "output: p=0.8990 elttil ynit\n",
      "output: p=0.0131 eltitl yinyv\n",
      "output: p=0.0063 elttli ynltv\n",
      "output: p=0.0045 elttil ynti\n",
      "output: p=0.0035 elttli ynlt\n",
      "output: p=0.0025 elttil ynitg\n",
      "output: p=0.0024 ehtltgztsnm\n",
      "output: p=0.0022 eltitl qyiwj\n",
      "output: p=0.0017 eltitl xiyp\n",
      "output: p=0.0016 eltitl yinym\n",
      "\n",
      "sentence:        pony\n",
      "target:          ynop\n",
      "output: p=0.9966 ynop\n",
      "output: p=0.0023 yonp\n",
      "output: p=0.0003 ynpo\n",
      "output: p=0.0003 oynp\n",
      "output: p=0.0001 yno\n",
      "output: p=0.0000 ynopz\n",
      "output: p=0.0000 nyop\n",
      "output: p=0.0000 ynopc\n",
      "output: p=0.0000 wyopc\n",
      "output: p=0.0000 nyopn\n",
      "\n",
      "sentence:        the quick brown fox\n",
      "target:          xof nworb kciuq eht\n",
      "output: p=0.2889 xofn worc\n",
      "output: p=0.1846 xof nworc\n",
      "output: p=0.1512 xfon wocz\n",
      "output: p=0.1234 xfon wozc\n",
      "output: p=0.0517 xfon worc\n",
      "output: p=0.0201 xfon owzc\n",
      "output: p=0.0194 xfon wozr\n",
      "output: p=0.0137 xfon worz\n",
      "output: p=0.0101 xfon wor\n",
      "output: p=0.0101 xofn wroc\n",
      "\n",
      "sentence:        abcdefghijklmnopqrstuvwxyz\n",
      "target:          zyxwvutsrqponmlkjihgfedcba\n",
      "output: p=0.2921 zyxwvutsrpqo\n",
      "output: p=0.0620 zyxwvtuspcot\n",
      "output: p=0.0400 zyxwvutsrpjo\n",
      "output: p=0.0388 zyxwvutszpo\n",
      "output: p=0.0313 zyxwvmisntf\n",
      "output: p=0.0220 zyxwvmsiqtno\n",
      "output: p=0.0213 zyxwvmsitnf\n",
      "output: p=0.0208 zyxwvmisqtnf\n",
      "output: p=0.0192 zyxwvutsrpqoj\n",
      "output: p=0.0172 zyxwvmsitnfo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_beam(sentence, num_options=10):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        model = Model(mode='inference')\n",
    "        model.build_graph()\n",
    "        with tf.train.MonitoredSession(\n",
    "                session_creator=tf.train.ChiefSessionCreator(checkpoint_dir=train_dir)) as sess:\n",
    "            state = sess.run(\n",
    "                model.encoder_output_state,\n",
    "                feed_dict={\n",
    "                    model.sentences: [encode_sentence(sentence)],\n",
    "                })\n",
    "            Option = collections.namedtuple(\n",
    "                'Option', ['p', 'sentence', 'state'])\n",
    "            options = [Option(p=1.0, sentence=GO, state=state)]\n",
    "            while True:\n",
    "                new_options = []\n",
    "                for option in options:\n",
    "                    c = option.sentence[-1]\n",
    "                    if c == EOS:\n",
    "                        new_options.append(option)\n",
    "                        continue\n",
    "                    state, probs = sess.run(\n",
    "                        [model.decoder_output_state, model.probs],\n",
    "                        feed_dict={\n",
    "                            model.decoder_input_state: option.state,\n",
    "                            model.decoder_inputs: [encode_sentence(c)],\n",
    "                        })\n",
    "                    probs = np.squeeze(probs)\n",
    "                    for i, p in enumerate(probs):\n",
    "                        c = id_to_char(i)\n",
    "                        new_option = Option(\n",
    "                            p=option.p * p,\n",
    "                            sentence=option.sentence + c,\n",
    "                            state=state)\n",
    "                        new_options.append(new_option)\n",
    "                options = list(\n",
    "                    sorted(new_options, key=lambda x: -x.p))[:num_options]\n",
    "                if all(option.sentence[-1] == EOS for option in options):\n",
    "                    break\n",
    "            return [(option.sentence[1:-1], option.p) for option in options]\n",
    "\n",
    "\n",
    "for sentence in ['abc', 'tiny little', 'pony', 'the quick brown fox', string.ascii_lowercase]:\n",
    "    print('sentence:        {}'.format(sentence))\n",
    "    print('target:          {}'.format(''.join(reversed(sentence))))\n",
    "    for option, prob in run_beam(sentence):\n",
    "        print('output: p={:.4f} {}'.format(prob, option))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
